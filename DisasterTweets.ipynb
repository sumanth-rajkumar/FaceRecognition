{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rH7Y95rzxlqt",
        "outputId": "877dcb92-3e1a-43b1-d297-fe833964369d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set:\n",
            "   id keyword location                                               text  \\\n",
            "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
            "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
            "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
            "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
            "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
            "\n",
            "   target  \n",
            "0       1  \n",
            "1       1  \n",
            "2       1  \n",
            "3       1  \n",
            "4       1  \n",
            "\n",
            "Test Set:\n",
            "   id keyword location                                               text\n",
            "0   0     NaN      NaN                 Just happened a terrible car crash\n",
            "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
            "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
            "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
            "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan\n",
            "\n",
            "Missing values in training set:\n",
            "id             0\n",
            "keyword       61\n",
            "location    2533\n",
            "text           0\n",
            "target         0\n",
            "dtype: int64\n",
            "\n",
            "Missing values in test set:\n",
            "id             0\n",
            "keyword       26\n",
            "location    1105\n",
            "text           0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the datasets\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "\n",
        "# Display first few rows of the training set\n",
        "print(\"Training Set:\")\n",
        "print(train.head())\n",
        "\n",
        "# Display first few rows of the test set\n",
        "print(\"\\nTest Set:\")\n",
        "print(test.head())\n",
        "\n",
        "# Check for missing values in the training set\n",
        "print(\"\\nMissing values in training set:\")\n",
        "print(train.isnull().sum())\n",
        "\n",
        "# Check for missing values in the test set\n",
        "print(\"\\nMissing values in test set:\")\n",
        "print(test.isnull().sum())\n",
        "\n",
        "# Visualize the distribution of the target variable\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(x='target', data=train)\n",
        "plt.title('Target Distribution')\n",
        "plt.xlabel('Target (0 = Not Disaster, 1 = Disaster)')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Fill missing values\n",
        "train['keyword'].fillna('Unknown', inplace=True)\n",
        "train['location'].fillna('Unknown', inplace=True)\n",
        "test['keyword'].fillna('Unknown', inplace=True)\n",
        "test['location'].fillna('Unknown', inplace=True)\n",
        "\n",
        "# Function to clean text\n",
        "def clean_text(text):\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    # Remove stopwords\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "    return text\n",
        "\n",
        "# Apply the clean_text function to the 'text' column\n",
        "train['cleaned_text'] = train['text'].apply(clean_text)\n",
        "test['cleaned_text'] = test['text'].apply(clean_text)\n",
        "\n",
        "# Display the first few rows to check\n",
        "print(\"Training Set with Cleaned Text:\")\n",
        "print(train[['text', 'cleaned_text']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1j4W81klx8uC",
        "outputId": "16aa4037-94f7-4fab-a424-a89ae3a61515"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "<ipython-input-2-865fa254abef>:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  train['keyword'].fillna('Unknown', inplace=True)\n",
            "<ipython-input-2-865fa254abef>:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  train['location'].fillna('Unknown', inplace=True)\n",
            "<ipython-input-2-865fa254abef>:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  test['keyword'].fillna('Unknown', inplace=True)\n",
            "<ipython-input-2-865fa254abef>:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  test['location'].fillna('Unknown', inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set with Cleaned Text:\n",
            "                                                text  \\\n",
            "0  Our Deeds are the Reason of this #earthquake M...   \n",
            "1             Forest fire near La Ronge Sask. Canada   \n",
            "2  All residents asked to 'shelter in place' are ...   \n",
            "3  13,000 people receive #wildfires evacuation or...   \n",
            "4  Just got sent this photo from Ruby #Alaska as ...   \n",
            "\n",
            "                                        cleaned_text  \n",
            "0       deeds reason earthquake may allah forgive us  \n",
            "1              forest fire near la ronge sask canada  \n",
            "2  residents asked shelter place notified officer...  \n",
            "3  13000 people receive wildfires evacuation orde...  \n",
            "4  got sent photo ruby alaska smoke wildfires pou...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Initialize TF-IDF Vectorizer\n",
        "tfidf = TfidfVectorizer(max_features=5000)  # Adjust max_features as needed\n",
        "\n",
        "# Fit and transform the training data; transform the test data\n",
        "X_train = tfidf.fit_transform(train['cleaned_text']).toarray()\n",
        "X_test = tfidf.transform(test['cleaned_text']).toarray()\n",
        "\n",
        "# Get the target variable\n",
        "y_train = train['target'].values\n",
        "\n",
        "# Display the shape of the transformed data\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deFLOrTmyBwz",
        "outputId": "782e9808-41a7-47dd-b423-3903080564ab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (7613, 5000)\n",
            "Shape of X_test: (3263, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "\n",
        "# Split the data for validation\n",
        "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the model\n",
        "model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "model.fit(X_train_split, y_train_split)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_val, y_pred))\n",
        "print(\"F1 Score:\", f1_score(y_val, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBbRcJxJyFjU",
        "outputId": "cba4e26f-26f5-4dd4-ab90-7b04dbfbad01"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.89      0.84       874\n",
            "           1       0.82      0.67      0.74       649\n",
            "\n",
            "    accuracy                           0.80      1523\n",
            "   macro avg       0.80      0.78      0.79      1523\n",
            "weighted avg       0.80      0.80      0.79      1523\n",
            "\n",
            "F1 Score: 0.7404902789518174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test set\n",
        "test_predictions = model.predict(X_test)\n",
        "\n",
        "# Create a submission DataFrame\n",
        "submission = pd.DataFrame({'id': test['id'], 'target': test_predictions})\n",
        "\n",
        "# Save the submission file\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(\"Submission file created successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8nZGiNrygYd",
        "outputId": "618b3df7-8536-43dc-e906-02283b1df10a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load GloVe embeddings\n",
        "embedding_index = {}\n",
        "with open('glove.6B.100d.txt', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.array(values[1:], dtype='float32')\n",
        "        embedding_index[word] = vector\n",
        "\n",
        "# Check the size of the loaded embeddings\n",
        "print(\"Number of words in GloVe embeddings:\", len(embedding_index))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJ7NCdIJyiC4",
        "outputId": "a55dfe0b-33ba-4f3c-dc73-962885da538d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in GloVe embeddings: 400001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum number of words and the embedding dimension\n",
        "MAX_NB_WORDS = 5000\n",
        "EMBEDDING_DIM = 100  # GloVe 100d\n",
        "\n",
        "# Tokenize and fit on the training data\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
        "tokenizer.fit_on_texts(train['cleaned_text'])\n",
        "\n",
        "# Convert text to sequences\n",
        "X_train_seq = tokenizer.texts_to_sequences(train['cleaned_text'])\n",
        "X_test_seq = tokenizer.texts_to_sequences(test['cleaned_text'])\n",
        "\n",
        "# Pad sequences to ensure uniform length\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=50)  # Adjust maxlen as needed\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=50)\n",
        "\n",
        "# Create embedding matrix\n",
        "word_index = tokenizer.word_index\n",
        "embedding_matrix = np.zeros((MAX_NB_WORDS, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    if i < MAX_NB_WORDS:\n",
        "        embedding_vector = embedding_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "\n",
        "print(\"Embedding matrix shape:\", embedding_matrix.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZimy7l1ys5M",
        "outputId": "adb7f1c1-0e07-41a7-fb5f-5a1fe2b1ca06"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding matrix shape: (5000, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, SpatialDropout1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Model parameters\n",
        "embedding_dim = EMBEDDING_DIM\n",
        "max_sequence_length = 50  # Same as the maxlen in padding\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=MAX_NB_WORDS,\n",
        "                    output_dim=embedding_dim,\n",
        "                    weights=[embedding_matrix],\n",
        "                    input_length=max_sequence_length,\n",
        "                    trainable=False))\n",
        "model.add(SpatialDropout1D(0.2))\n",
        "model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=1e-3), metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_pad, y_train, batch_size=64, epochs=5, validation_split=0.2, verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YACXWqJHyyPl",
        "outputId": "610b1ca6-ceca-4301-d694-e3357f162f4c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 78ms/step - accuracy: 0.6812 - loss: 0.5966 - val_accuracy: 0.7938 - val_loss: 0.4532\n",
            "Epoch 2/5\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 77ms/step - accuracy: 0.7837 - loss: 0.4818 - val_accuracy: 0.7958 - val_loss: 0.4424\n",
            "Epoch 3/5\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 74ms/step - accuracy: 0.7768 - loss: 0.4809 - val_accuracy: 0.7925 - val_loss: 0.4452\n",
            "Epoch 4/5\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 92ms/step - accuracy: 0.7884 - loss: 0.4651 - val_accuracy: 0.7997 - val_loss: 0.4410\n",
            "Epoch 5/5\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 99ms/step - accuracy: 0.7965 - loss: 0.4480 - val_accuracy: 0.8056 - val_loss: 0.4372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test set\n",
        "test_predictions = (model.predict(X_test_pad) > 0.5).astype(\"int32\")\n",
        "\n",
        "# Create a submission DataFrame\n",
        "submission = pd.DataFrame({'id': test['id'], 'target': test_predictions.flatten()})\n",
        "\n",
        "# Save the submission file\n",
        "submission.to_csv('submission_lstm.csv', index=False)\n",
        "print(\"Submission file created successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvguZD8PzY_k",
        "outputId": "455d778d-bc65-4953-925d-2094dc70a733"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step\n",
            "Submission file created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize data\n",
        "def tokenize_data(texts, max_length=128):\n",
        "    return tokenizer(texts, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
        "\n",
        "# Apply tokenization to train and test sets\n",
        "train_encodings = tokenize_data(train['text'].tolist())\n",
        "test_encodings = tokenize_data(test['text'].tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFeBuF7izdRg",
        "outputId": "9a2003dd-fe55-497f-d12d-8ddc1948c352"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, AdamW\n",
        "\n",
        "# Load pre-trained BERT model with a classification head\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNj1Cpwjzr-0",
        "outputId": "14e5f6f8-b62a-4dad-a1e1-ef162054ff76"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Convert labels to tensor\n",
        "labels = torch.tensor(train['target'].values)\n",
        "\n",
        "# Create dataset and data loader\n",
        "train_dataset = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], labels)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n"
      ],
      "metadata": {
        "id": "wLNsZUlMzwRu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Training function\n",
        "epochs = 3\n",
        "model.train()\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        # Move batch to device\n",
        "        batch = [item.to(device) for item in batch]\n",
        "        input_ids, attention_mask, labels = batch\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} - Loss: {avg_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_gGk1SKGwHR",
        "outputId": "c3891b39-37ab-4626-bb7d-ec8c5c6dc1d2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 - Loss: 0.4352\n",
            "Epoch 2/3 - Loss: 0.3144\n",
            "Epoch 3/3 - Loss: 0.2328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Switch to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tokenize test data for BERT and move it to the device\n",
        "with torch.no_grad():\n",
        "    test_inputs = test_encodings['input_ids'].to(device)\n",
        "    test_masks = test_encodings['attention_mask'].to(device)\n",
        "\n",
        "    # Get predictions\n",
        "    outputs = model(test_inputs, attention_mask=test_masks)\n",
        "    predictions = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
        "\n",
        "# Create a submission DataFrame\n",
        "submission = pd.DataFrame({'id': test['id'], 'target': predictions})\n",
        "submission.to_csv('submission_bert.csv', index=False)\n",
        "print(\"Submission file created successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjQoRNMxskqx",
        "outputId": "d51a3a3d-148f-4dcf-e01f-74131885e213"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file created successfully.\n"
          ]
        }
      ]
    }
  ]
}